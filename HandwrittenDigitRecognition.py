# mnist_dual_model_gui_v5.py
import os

from tensorflow import timestamp

os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"
# os.environ["CUDA_VISIBLE_DEVICES"] = "-1" # å¯é€‰ï¼šå¦‚æœæƒ³å¼ºåˆ¶CPUè¿è¡Œï¼Œå–æ¶ˆæ³¨é‡Š

import sys, io, time, pickle, random
from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QWidget, QLabel, QPushButton, QVBoxLayout, QHBoxLayout,
    QFrame, QMessageBox, QProgressBar, QFileDialog, QCheckBox, QLineEdit, QComboBox, QInputDialog
)
from PyQt5.QtGui import QPainter, QPixmap, QPen, QColor, QImage
from PyQt5.QtCore import Qt, QPoint, QThread, pyqtSignal
from PIL import Image, ImageOps
import numpy as np

MODEL_CNN = "mnist_cnn.h5"
MODEL_SVM = "mnist_svm.pkl"


# ========== ç»˜å›¾ç”»å¸ƒ ==========
class PaintCanvas(QLabel):
    def __init__(self, parent=None, pen_width=22, size=320):
        super().__init__(parent)
        self.size_px = size
        self.setFixedSize(self.size_px, self.size_px)
        self.pix = QPixmap(self.size_px, self.size_px)
        self.pix.fill(Qt.white)
        self.setPixmap(self.pix)
        self.drawing = False
        self.last_point = QPoint()
        self.pen_width = pen_width
        self.pen_color = QColor(0, 0, 0)
        self.setFrameStyle(QFrame.StyledPanel | QFrame.Plain)

    def set_pen_width(self, w):
        self.pen_width = w

    def mousePressEvent(self, e):
        if e.button() == Qt.LeftButton:
            self.drawing = True
            self.last_point = e.pos()
            self._draw_point(self.last_point)

    def mouseMoveEvent(self, e):
        if self.drawing:
            self._draw_line(e.pos())

    def mouseReleaseEvent(self, e):
        if e.button() == Qt.LeftButton:
            self.drawing = False

    def _draw_point(self, pt):
        p = QPainter(self.pix)
        pen = QPen(self.pen_color, self.pen_width, Qt.SolidLine, Qt.RoundCap, Qt.RoundJoin)
        p.setPen(pen)
        p.drawPoint(pt)
        p.end()
        self.setPixmap(self.pix)

    def _draw_line(self, pos):
        p = QPainter(self.pix)
        pen = QPen(self.pen_color, self.pen_width, Qt.SolidLine, Qt.RoundCap, Qt.RoundJoin)
        p.setPen(pen)
        p.drawLine(self.last_point, pos)
        p.end()
        self.last_point = QPoint(pos)
        self.setPixmap(self.pix)

    def clear(self):
        self.pix.fill(Qt.white)
        self.setPixmap(self.pix)

    def get_image_pil(self):
        from PyQt5.QtCore import QBuffer, QIODevice
        buf = QBuffer()
        buf.open(QIODevice.ReadWrite)
        self.pix.save(buf, "PNG")
        return Image.open(io.BytesIO(buf.data()))

    # ä¿®æ”¹ï¼šä½¿ç”¨ QImage è€Œä¸æ˜¯ PIL çš„ toqpixmap
    def set_image_pil(self, pil_image):
        # å°† PIL å›¾åƒè½¬æ¢ä¸º RGB æ¨¡å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
        pil_image = pil_image.convert("RGB")
        # è·å–å›¾åƒæ•°æ®
        data = pil_image.tobytes("raw", "RGB")
        # åˆ›å»º QImage
        # å‚æ•°: bytes_data, width, height, bytes_per_line, format
        qimg = QImage(data, pil_image.width, pil_image.height, pil_image.width * 3, QImage.Format_RGB888)
        # åˆ›å»º QPixmap å¹¶è®¾ç½®åˆ°ç”»å¸ƒ
        pixmap = QPixmap.fromImage(qimg)
        self.pix = pixmap
        self.setPixmap(self.pix)


# ========== å›¾åƒé¢„å¤„ç† ==========
def preprocess_pil_image(pil, flatten=False):
    pil = pil.convert('L')
    img = np.array(pil)
    img = 255 - img
    img = (img > 50) * 255
    coords = np.column_stack(np.where(img > 0))
    if coords.size == 0:
        img = Image.new('L', (28, 28), 0)
        img_array = np.array(img).astype('float32') / 255.0
        return img_array.reshape(1, -1) if flatten else img_array.reshape(1, 28, 28, 1)

    y0, x0 = coords.min(axis=0)
    y1, x1 = coords.max(axis=0)
    img_cropped = img[y0:y1 + 1, x0:x1 + 1]
    img_pil = Image.fromarray(img_cropped)
    img_pil = ImageOps.fit(img_pil, (28, 28), Image.LANCZOS)
    img_array = np.array(img_pil).astype('float32') / 255.0

    if flatten:
        return img_array.reshape(1, -1)
    else:
        return img_array.reshape(1, 28, 28, 1)


# ========== CNN è®­ç»ƒçº¿ç¨‹ ==========
class CNNTrainThread(QThread):
    progress = pyqtSignal(str)
    done = pyqtSignal(float, float)
    error = pyqtSignal(str)

    def __init__(self, epochs=3):
        super().__init__()
        self.epochs = epochs

    def run(self):
        try:
            import tensorflow as tf
            from tensorflow.keras.utils import to_categorical
            from tensorflow.keras.datasets import mnist
            from tensorflow.keras.models import Sequential
            from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

            print("ğŸ“¦ [CNN] åŠ è½½ MNIST æ•°æ®...")
            self.progress.emit("åŠ è½½ MNIST æ•°æ®...")
            (x_train, y_train), (x_test, y_test) = mnist.load_data()
            x_train = x_train.astype('float32') / 255.0
            x_test = x_test.astype('float32') / 255.0
            x_train = np.expand_dims(x_train, -1)
            x_test = np.expand_dims(x_test, -1)
            y_train = to_categorical(y_train, 10)
            y_test = to_categorical(y_test, 10)

            model = Sequential([
                Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),
                MaxPooling2D((2, 2)),
                Conv2D(32, (3, 3), activation='relu'),
                MaxPooling2D((2, 2)),
                Flatten(),
                Dense(64, activation='relu'),
                Dropout(0.25),
                Dense(10, activation='softmax')
            ])
            model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

            start = time.time()
            for e in range(self.epochs):
                print(f"ğŸš€ [CNN] ç¬¬ {e + 1}/{self.epochs} è½®è®­ç»ƒä¸­...")
                self.progress.emit(f"CNN è®­ç»ƒç¬¬ {e + 1}/{self.epochs} è½®...")
                model.fit(x_train, y_train, batch_size=128, epochs=1, validation_split=0.1, verbose=1)
            loss, acc = model.evaluate(x_test, y_test, verbose=0)
            elapsed = time.time() - start
            model.save(MODEL_CNN)
            self.done.emit(acc, elapsed)
        except Exception as e:
            self.error.emit(str(e))
            print("âŒ [CNN] é”™è¯¯:", e)


# ========== SVM è®­ç»ƒçº¿ç¨‹ ==========
class SVMTrainThread(QThread):
    progress = pyqtSignal(str)
    done = pyqtSignal(float, float)
    error = pyqtSignal(str)

    def run(self):
        try:
            from sklearn import svm, metrics
            from skimage.feature import hog
            from tensorflow.keras.datasets import mnist

            self.progress.emit("åŠ è½½ MNIST æ•°æ®å¹¶æå– HOG ç‰¹å¾...")
            print("ğŸ“¦ [SVM] æ­£åœ¨åŠ è½½ MNIST æ•°æ®å¹¶æå–ç‰¹å¾...")
            (x_train, y_train), (x_test, y_test) = mnist.load_data()

            def extract_hog(images):
                feats = []
                for i, img in enumerate(images):
                    feats.append(hog(img, orientations=9, pixels_per_cell=(4, 4),
                                     cells_per_block=(2, 2), block_norm='L2-Hys'))
                    if i % 20 == 0:
                        print(f"ğŸŒ€ [SVM] ç‰¹å¾æå–è¿›åº¦: {i}/{len(images)}")
                return np.array(feats)

            start = time.time()
            X_train = extract_hog(x_train[:20000])
            X_test = extract_hog(x_test[:5000])
            y_train = y_train[:20000]
            y_test = y_test[:5000]

            self.progress.emit("è®­ç»ƒ SVM æ¨¡å‹ä¸­...")
            print("ğŸš€ [SVM] å¼€å§‹è®­ç»ƒ...")
            clf = svm.SVC(kernel='linear', probability=True)
            clf.fit(X_train, y_train)

            acc = metrics.accuracy_score(y_test, clf.predict(X_test))
            elapsed = time.time() - start
            with open(MODEL_SVM, "wb") as f:
                pickle.dump(clf, f)
            self.done.emit(acc, elapsed)
        except Exception as e:
            self.error.emit(str(e))
            print("âŒ [SVM] é”™è¯¯:", e)


# ========== CNNå†è®­ç»ƒçº¿ç¨‹ ==========
class CNNReTrainThread(QThread):
    progress = pyqtSignal(str)
    done = pyqtSignal(float)  # åªè¿”å›æ–°å‡†ç¡®ç‡ï¼Œå› ä¸ºè®­ç»ƒå¾ˆå¿«
    error = pyqtSignal(str)

    def __init__(self, feedback_images, feedback_labels, epochs=1):
        super().__init__()
        self.feedback_images = feedback_images
        self.feedback_labels = feedback_labels
        self.epochs = epochs

    def run(self):
        try:
            import tensorflow as tf
            from tensorflow.keras.models import load_model
            from tensorflow.keras.utils import to_categorical

            print(f"ğŸ”„ [CNN] åŠ è½½ç°æœ‰æ¨¡å‹è¿›è¡Œå†è®­ç»ƒ...")
            self.progress.emit("åŠ è½½ç°æœ‰æ¨¡å‹...")
            model = load_model(MODEL_CNN)

            # é¢„å¤„ç†åé¦ˆå›¾åƒ
            # preprocess_pil_image è¿”å› (1, 28, 28, 1) å½¢çŠ¶
            processed_image_list = []
            for img in self.feedback_images:
                processed_img = preprocess_pil_image(img, flatten=False)  # å¾—åˆ° (1, 28, 28, 1)
                processed_image_list.append(processed_img[0])  # å–å‡º (28, 28, 1) éƒ¨åˆ†
            # å †å æˆ (num_samples, 28, 28, 1)
            processed_images = np.stack(processed_image_list, axis=0)
            processed_labels = to_categorical(self.feedback_labels, 10)

            print(f"ğŸ”„ [CNN] ä½¿ç”¨ {len(processed_images)} ä¸ªåé¦ˆæ ·æœ¬è¿›è¡Œå†è®­ç»ƒ...")
            print(f"Input shape: {processed_images.shape}, Label shape: {processed_labels.shape}")
            self.progress.emit(f"ä½¿ç”¨ {len(processed_images)} ä¸ªåé¦ˆæ ·æœ¬å†è®­ç»ƒ {self.epochs} è½®...")

            # è¿›è¡Œå¢é‡è®­ç»ƒ
            model.fit(processed_images, processed_labels, batch_size=32, epochs=self.epochs, verbose=1)

            # ä¿å­˜æ›´æ–°åçš„æ¨¡å‹
            model.save(MODEL_CNN)
            print("âœ… [CNN] å†è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²æ›´æ–°ã€‚")
            self.progress.emit("å†è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²æ›´æ–°ã€‚")
            # è¿™é‡Œå¯ä»¥ç®€å•è¯„ä¼°ï¼Œä½†é€šå¸¸æˆ‘ä»¬ä¼šç”¨ä¸€ä¸ªå›ºå®šçš„éªŒè¯é›†æ¥è¯„ä¼°
            # å‡è®¾ç”¨MNISTæµ‹è¯•é›†è¯„ä¼°
            (_, _), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
            x_test = x_test.astype('float32') / 255.0
            x_test = np.expand_dims(x_test, -1)
            y_test_cat = to_categorical(y_test, 10)
            _, acc = model.evaluate(x_test, y_test_cat, verbose=0)
            self.done.emit(acc)

        except Exception as e:
            self.error.emit(str(e))
            print("âŒ [CNN] å†è®­ç»ƒé”™è¯¯:", e)


# ========== MNISTæ•°æ®åŠ è½½çº¿ç¨‹ ==========
class MNISTLoadThread(QThread):
    data_loaded = pyqtSignal(object, object)  # ä¿¡å·ï¼šå‘é€åŠ è½½å®Œæˆçš„æ•°æ®
    error = pyqtSignal(str)  # ä¿¡å·ï¼šå‘é€é”™è¯¯ä¿¡æ¯

    def run(self):
        try:
            print("ğŸ“¦ åå°åŠ è½½MNISTæµ‹è¯•é›†...")
            from tensorflow.keras.datasets import mnist
            (_, _), (x_test, y_test) = mnist.load_data()
            # å‘é€åŠ è½½å®Œæˆçš„æ•°æ®ç»™ä¸»çº¿ç¨‹
            self.data_loaded.emit(x_test, y_test)
            print("âœ… MNISTæµ‹è¯•é›†åŠ è½½å®Œæˆ")
        except Exception as e:
            # å‘é€é”™è¯¯ä¿¡æ¯ç»™ä¸»çº¿ç¨‹
            self.error.emit(str(e))


# ========== ä¸»çª—å£ ==========
class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("æ‰‹å†™æ•°å­—è¯†åˆ«")
        self.setMinimumSize(950, 550)
        self.model = None
        self.model_type = "CNN"
        # ä¿®æ”¹ï¼šç§»é™¤ç›´æ¥å­˜å‚¨æ•°æ®çš„å˜é‡ï¼Œæ”¹ä¸ºå­˜å‚¨çº¿ç¨‹å¼•ç”¨
        self.mnist_thread = None
        self.mnist_test_images = None
        self.mnist_test_labels = None
        # æ–°å¢ï¼šå­˜å‚¨åé¦ˆæ•°æ®
        self.feedback_data = []  # List of (PIL_image, label)
        self._init_ui()

    def _init_ui(self):
        c = QWidget()
        self.setCentralWidget(c)
        layout = QHBoxLayout(c)
        left = QVBoxLayout()
        right = QVBoxLayout()
        layout.addLayout(left, 2)
        layout.addLayout(right, 1)

        self.canvas = PaintCanvas(size=360, pen_width=20)
        left.addWidget(self.canvas, alignment=Qt.AlignCenter)

        # æŒ‰é’®è¡Œï¼šæ¸…é™¤ã€ä¿å­˜ã€éšæœºMNIST
        btn_row = QHBoxLayout()
        for text, color, fn in [("æ¸…é™¤", "#ef5350", self.canvas.clear),
                                ("ä¿å­˜", "#42a5f5", self._save),
                                ("éšæœºMNIST", "#9ccc65", self._load_random_mnist)]:  # æ·»åŠ æ–°æŒ‰é’®
            b = QPushButton(text)
            b.setStyleSheet(f"background:{color};color:white;border:none;border-radius:6px;")
            b.setFixedHeight(36)
            b.clicked.connect(fn)
            btn_row.addWidget(b)
        left.addLayout(btn_row)

        # æ¨¡å‹é€‰æ‹©ä¸åŠ è½½
        model_row = QHBoxLayout()
        model_row.addWidget(QLabel("è¯†åˆ«æ–¹å¼ï¼š"))
        self.model_selector = QComboBox()
        self.model_selector.addItems(["CNN", "HOG+SVM"])
        self.model_selector.currentTextChanged.connect(self._change_model_type)
        model_row.addWidget(self.model_selector)

        self.load_btn = QPushButton("åŠ è½½æ¨¡å‹")
        self.load_btn.clicked.connect(self._load_model)
        model_row.addWidget(self.load_btn)
        left.addLayout(model_row)

        # è®­ç»ƒæ§åˆ¶
        train_row = QHBoxLayout()
        self.train_btn = QPushButton("è®­ç»ƒæ¨¡å‹")
        self.train_btn.clicked.connect(self._train)
        self.epoch_input = QLineEdit("3")
        self.epoch_input.setFixedWidth(60)
        train_row.addWidget(self.train_btn)
        train_row.addWidget(QLabel("è½®æ•°ï¼š"))
        train_row.addWidget(self.epoch_input)
        left.addLayout(train_row)

        # æ–°å¢ï¼šå†è®­ç»ƒæŒ‰é’® (ä»…å¯¹CNNæœ‰æ•ˆ)
        self.retrain_btn = QPushButton("ä½¿ç”¨åé¦ˆæ•°æ®å†è®­ç»ƒ (CNN)")
        self.retrain_btn.clicked.connect(self._retrain_with_feedback)
        left.addWidget(self.retrain_btn)

        # å³ä¾§ï¼šç»“æœå’Œæ¦‚ç‡åˆ†å¸ƒ
        self.status = QLabel("çŠ¶æ€ï¼šæœªåŠ è½½æ¨¡å‹")
        right.addWidget(self.status)
        self.pred_label = QLabel("-")
        self.pred_label.setStyleSheet("font-size:72px; font-weight:bold;")
        right.addWidget(self.pred_label)

        self.bars = []
        for i in range(10):
            h = QHBoxLayout()
            l = QLabel(f"{i}:")
            p = QProgressBar()
            p.setRange(0, 1000)
            h.addWidget(l)
            h.addWidget(p)
            right.addLayout(h)
            self.bars.append(p)

        # é¢„æµ‹å’Œåé¦ˆæŒ‰é’®è¡Œ
        pred_btn_row = QHBoxLayout()
        self.predict_btn = QPushButton("è¯†åˆ«")
        self.predict_btn.clicked.connect(self._predict)
        pred_btn_row.addWidget(self.predict_btn)

        self.feedback_btn = QPushButton("åé¦ˆ")
        self.feedback_btn.clicked.connect(self._request_feedback)
        pred_btn_row.addWidget(self.feedback_btn)
        right.addLayout(pred_btn_row)

    def _change_model_type(self, text):
        self.model_type = text
        self.model = None
        self._set_status(f"åˆ‡æ¢ä¸º {text} æ¨¡å¼")

    def _set_status(self, msg, err=False):
        self.status.setText(("âŒ " if err else "âœ… ") + msg)

    def _train(self):
        if self.model_type == "CNN":
            try:
                epochs = int(self.epoch_input.text())
            except:
                QMessageBox.warning(self, "é”™è¯¯", "è¯·è¾“å…¥æ•´æ•°è½®æ•°")
                return
            print(f"\n==================== å¼€å§‹ CNN è®­ç»ƒ ({epochs} epoch) ====================")
            self.thread = CNNTrainThread(epochs)
        else:
            print("\n==================== å¼€å§‹ HOG+SVM è®­ç»ƒ ====================")
            self.thread = SVMTrainThread()

        self.thread.progress.connect(lambda s: self._set_status(s))
        self.thread.done.connect(self._on_train_done)
        self.thread.error.connect(lambda e: self._set_status(e, True))
        self.thread.start()

    def _on_train_done(self, acc, elapsed):
        self._set_status(f"{self.model_type} è®­ç»ƒå®Œæˆ acc={acc:.4f}ï¼Œè€—æ—¶ {elapsed:.1f} ç§’")
        QMessageBox.information(self, "è®­ç»ƒå®Œæˆ",
                                f"{self.model_type} æ¨¡å‹è®­ç»ƒå®Œæˆï¼\nå‡†ç¡®ç‡ï¼š{acc:.4f}\nè€—æ—¶ï¼š{elapsed:.1f} ç§’")
        self.model = None

    def _load_model(self):
        try:
            if self.model_type == "CNN":
                from tensorflow.keras.models import load_model
                self.model = load_model(MODEL_CNN)
            else:
                with open(MODEL_SVM, "rb") as f:
                    self.model = pickle.load(f)
            self._set_status(f"{self.model_type} æ¨¡å‹å·²åŠ è½½")
        except Exception as e:
            self._set_status(f"åŠ è½½å¤±è´¥ï¼š{e}", True)

    def _predict(self):
        pil = self.canvas.get_image_pil()
        if self.model is None:
            QMessageBox.warning(self, "é”™è¯¯", "è¯·å…ˆåŠ è½½æˆ–è®­ç»ƒæ¨¡å‹ï¼")
            return

        if self.model_type == "CNN":
            x = preprocess_pil_image(pil)
            preds = self.model.predict(x, verbose=0)[0]
        else:
            from skimage.feature import hog
            img = preprocess_pil_image(pil, flatten=False).reshape(28, 28)
            feat = hog(img, orientations=9, pixels_per_cell=(4, 4),
                       cells_per_block=(2, 2), block_norm='L2-Hys').reshape(1, -1)
            preds = self.model.predict_proba(feat)[0]

        idx = int(np.argmax(preds))
        self.pred_label.setText(str(idx))

        for i, p in enumerate(preds):
            self.bars[i].setValue(int(p * 1000))
            self.bars[i].setFormat(f"{p * 100:.1f}%")

        self._set_status(f"{self.model_type} é¢„æµ‹å®Œæˆï¼š{idx}")

    def _save(self):
        timestamp = int(time.time())
        fname, _ = QFileDialog.getSaveFileName(self, "ä¿å­˜å›¾åƒ", f"digit_{timestamp}.png", "PNG Files (*.png)")
        if fname:
            self.canvas.get_image_pil().save(fname)

    def _load_random_mnist(self):
        """åŠ è½½éšæœºMNISTå›¾ç‰‡åˆ°ç”»å¸ƒå¹¶è¿›è¡Œè¯†åˆ«"""
        # å¦‚æœæ•°æ®å·²ç»åŠ è½½ï¼Œåˆ™ç›´æ¥å¤„ç†
        if self.mnist_test_images is not None and self.mnist_test_labels is not None:
            print("ğŸ”„ ä½¿ç”¨å·²ç¼“å­˜çš„MNISTæ•°æ®")
            self._process_random_mnist()
            return

        # å¦‚æœæ•°æ®æœªåŠ è½½ä¸”æ²¡æœ‰æ­£åœ¨è¿›è¡Œçš„åŠ è½½çº¿ç¨‹ï¼Œåˆ™å¯åŠ¨æ–°çº¿ç¨‹
        if self.mnist_thread is None or not self.mnist_thread.isRunning():
            print("ğŸ”„ å¯åŠ¨MNISTæ•°æ®åŠ è½½çº¿ç¨‹")
            self.mnist_thread = MNISTLoadThread()
            # è¿æ¥çº¿ç¨‹çš„ä¿¡å·
            self.mnist_thread.data_loaded.connect(self._on_mnist_loaded)
            self.mnist_thread.error.connect(lambda e: self._set_status(f"åŠ è½½MNISTæ•°æ®é›†å¤±è´¥ï¼š{e}", True))
            self.mnist_thread.start()
            self._set_status("æ­£åœ¨åŠ è½½MNISTæ•°æ®é›†...")
        else:
            # å¦‚æœçº¿ç¨‹æ­£åœ¨è¿è¡Œï¼Œå¯ä»¥æç¤ºç”¨æˆ·ç¨ç­‰
            self._set_status("MNISTæ•°æ®é›†åŠ è½½ä¸­ï¼Œè¯·ç¨å€™...")

    def _on_mnist_loaded(self, x_test, y_test):
        """æ¥æ”¶MNISTåŠ è½½çº¿ç¨‹å®Œæˆåçš„æ•°æ®"""
        # å°†åŠ è½½çš„æ•°æ®å­˜å‚¨åˆ°å®ä¾‹å˜é‡ä¸­
        self.mnist_test_images = x_test
        self.mnist_test_labels = y_test
        # æ•°æ®åŠ è½½å®Œæˆåï¼Œå¤„ç†éšæœºå›¾ç‰‡
        self._process_random_mnist()

    def _process_random_mnist(self):
        """å¤„ç†éšæœºé€‰æ‹©çš„MNISTå›¾ç‰‡ï¼ˆåœ¨æ•°æ®å·²åŠ è½½åè°ƒç”¨ï¼‰"""
        # éšæœºé€‰æ‹©ä¸€å¼ å›¾ç‰‡
        random_index = random.randint(0, len(self.mnist_test_images) - 1)
        selected_image_array = self.mnist_test_images[random_index]
        true_label = int(self.mnist_test_labels[random_index])

        # --- å…³é”®ä¿®æ”¹ï¼šç›´æ¥å¯¹åŸå§‹MNISTæ•°ç»„è¿›è¡Œä¸è®­ç»ƒæ—¶ç›¸åŒçš„é¢„å¤„ç† ---
        # 1. è½¬æ¢ä¸ºfloat32å¹¶å½’ä¸€åŒ–
        x = selected_image_array.astype('float32') / 255.0
        # 2. æ·»åŠ é€šé“ç»´åº¦ (28, 28) -> (28, 28, 1)
        x = np.expand_dims(x, -1)
        # 3. æ·»åŠ æ‰¹æ¬¡ç»´åº¦ (28, 28, 1) -> (1, 28, 28, 1)
        x = np.expand_dims(x, 0)
        # é¢„å¤„ç†å®Œæˆï¼Œx çš„å½¢çŠ¶ç°åœ¨æ˜¯ (1, 28, 28, 1)ï¼Œä¸è®­ç»ƒæ—¶ä¸€è‡´

        # --- ä¿æŒåŸå§‹å›¾åƒç”¨äºæ˜¾ç¤ºï¼ˆå¯é€‰ï¼‰ ---
        # å°†åŸå§‹MNISTæ•°ç»„è½¬æ¢ä¸ºPILå›¾åƒç”¨äºæ˜¾ç¤º
        pil_img = Image.fromarray(selected_image_array.astype('uint8'))
        pil_img_rgb = pil_img.convert("RGB")
        # å°†å›¾ç‰‡å°ºå¯¸è°ƒæ•´åˆ°ç”»å¸ƒå¤§å° (360x360)
        resized_img = pil_img_rgb.resize((self.canvas.size_px, self.canvas.size_px), Image.LANCZOS)
        # è®¾ç½®åˆ°ç”»å¸ƒä¸Š
        self.canvas.set_image_pil(resized_img)

        # --- ä½¿ç”¨é¢„å¤„ç†åçš„æ•°æ®è¿›è¡Œé¢„æµ‹ ---
        if self.model is not None and self.model_type == "CNN":
            try:
                # ç›´æ¥ä½¿ç”¨é¢„å¤„ç†å¥½çš„ x è¿›è¡Œé¢„æµ‹
                preds = self.model.predict(x, verbose=0)[0]  # verbose=0 é¿å…æ‰“å°è¿›åº¦
                idx = int(np.argmax(preds))

                # --- æ›´æ–°UI ---
                # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                self.pred_label.setText(str(idx))
                # æ›´æ–°æ¦‚ç‡æ¡
                for i, p in enumerate(preds):
                    self.bars[i].setValue(int(p * 1000))
                    self.bars[i].setFormat(f"{p * 100:.1f}%")

                # åœ¨çŠ¶æ€æ æ˜¾ç¤ºçœŸå®æ ‡ç­¾å’Œé¢„æµ‹ç»“æœ
                status_msg = f"éšæœºMNISTå›¾ç‰‡åŠ è½½å®Œæˆï¼ŒçœŸå®æ ‡ç­¾: {true_label}ï¼Œæ¨¡å‹é¢„æµ‹: {idx}"
                if idx == true_label:
                    self._set_status(status_msg + " (æ­£ç¡®)")
                else:
                    self._set_status(status_msg + " (é”™è¯¯)", err=True)
            except Exception as e:
                self._set_status(f"é¢„æµ‹æ—¶å‘ç”Ÿé”™è¯¯: {e}", err=True)
        elif self.model is not None and self.model_type == "HOG+SVM":
            # SVM ä½¿ç”¨ HOG ç‰¹å¾ï¼Œéœ€è¦ä¸“é—¨çš„é¢„å¤„ç†
            from skimage.feature import hog
            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨çš„é¢„å¤„ç†ä¹Ÿåº”ä¸SVMè®­ç»ƒæ—¶ä¸€è‡´
            # x æ˜¯ (1, 28, 28, 1)ï¼Œå–ç¬¬ä¸€ä¸ªæ ·æœ¬å¹¶ç§»é™¤é€šé“ç»´åº¦å¾—åˆ° (28, 28)
            img_for_hog = x[0].reshape(28, 28)
            feat = hog(img_for_hog, orientations=9, pixels_per_cell=(4, 4),
                       cells_per_block=(2, 2), block_norm='L2-Hys').reshape(1, -1)
            try:
                preds = self.model.predict_proba(feat)[0]
                idx = int(np.argmax(preds))

                # --- æ›´æ–°UI ---
                self.pred_label.setText(str(idx))
                for i, p in enumerate(preds):
                    self.bars[i].setValue(int(p * 1000))
                    self.bars[i].setFormat(f"{p * 100:.1f}%")

                status_msg = f"éšæœºMNISTå›¾ç‰‡åŠ è½½å®Œæˆï¼ŒçœŸå®æ ‡ç­¾: {true_label}ï¼Œæ¨¡å‹é¢„æµ‹: {idx}"
                if idx == true_label:
                    self._set_status(status_msg + " (æ­£ç¡®)")
                else:
                    self._set_status(status_msg + " (é”™è¯¯)", err=True)
            except Exception as e:
                self._set_status(f"é¢„æµ‹æ—¶å‘ç”Ÿé”™è¯¯: {e}", err=True)
        else:
            # å¦‚æœæ¨¡å‹æœªåŠ è½½
            self._set_status(f"éšæœºMNISTå›¾ç‰‡åŠ è½½å®Œæˆï¼ŒçœŸå®æ ‡ç­¾: {true_label} (è¯·å…ˆåŠ è½½æ¨¡å‹è¿›è¡Œé¢„æµ‹)")
            # ä»ç„¶å°†å›¾åƒæ˜¾ç¤ºåœ¨ç”»å¸ƒä¸Š

    def _request_feedback(self):
        """è¯·æ±‚ç”¨æˆ·è¾“å…¥æ­£ç¡®çš„æ ‡ç­¾"""
        if self.model is None:
            QMessageBox.warning(self, "é”™è¯¯", "è¯·å…ˆåŠ è½½æˆ–è®­ç»ƒæ¨¡å‹ï¼")
            return

        # è·å–å½“å‰ç”»å¸ƒå›¾åƒ
        current_image = self.canvas.get_image_pil()
        if current_image is None:
            QMessageBox.warning(self, "é”™è¯¯", "ç”»å¸ƒä¸ºç©ºï¼Œæ— æ³•åé¦ˆã€‚")
            return

        # å¼¹å‡ºè¾“å…¥å¯¹è¯æ¡†
        correct_label, ok = QInputDialog.getInt(self, "åé¦ˆ", "è¯†åˆ«é”™è¯¯ï¼Œè¯·è¾“å…¥æ­£ç¡®çš„æ•°å­— (0-9):", 0, 0, 9)
        if ok:
            # å°†å›¾åƒå’Œç”¨æˆ·è¾“å…¥çš„æ ‡ç­¾æ·»åŠ åˆ°åé¦ˆåˆ—è¡¨
            self.feedback_data.append((current_image, correct_label))
            self._set_status(f"åé¦ˆå·²è®°å½•: æ ‡ç­¾ {correct_label}ã€‚å½“å‰åé¦ˆæ± å¤§å°: {len(self.feedback_data)}")

    def _retrain_with_feedback(self):
        """ä½¿ç”¨åé¦ˆæ•°æ®å¯¹CNNæ¨¡å‹è¿›è¡Œå†è®­ç»ƒ"""
        if self.model_type != "CNN":
            QMessageBox.warning(self, "é”™è¯¯", "å†è®­ç»ƒåŠŸèƒ½ä»…é€‚ç”¨äºCNNæ¨¡å‹ã€‚")
            return

        if not self.feedback_data:
            QMessageBox.information(self, "ä¿¡æ¯", "æ²¡æœ‰åé¦ˆæ•°æ®å¯ç”¨äºå†è®­ç»ƒã€‚")
            return

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
        if not os.path.exists(MODEL_CNN):
            QMessageBox.warning(self, "é”™è¯¯", f"æ¨¡å‹æ–‡ä»¶ {MODEL_CNN} ä¸å­˜åœ¨ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹ã€‚")
            return

        print(f"\n==================== å¼€å§‹ä½¿ç”¨ {len(self.feedback_data)} ä¸ªåé¦ˆæ ·æœ¬è¿›è¡ŒCNNå†è®­ç»ƒ ====================")
        # æå–å›¾åƒå’Œæ ‡ç­¾
        images, labels = zip(*self.feedback_data)
        self.retrain_thread = CNNReTrainThread(list(images), list(labels))
        self.retrain_thread.progress.connect(lambda s: self._set_status(s))
        self.retrain_thread.done.connect(self._on_retrain_done)
        self.retrain_thread.error.connect(lambda e: self._set_status(f"å†è®­ç»ƒå¤±è´¥: {e}", True))
        self.retrain_thread.start()

    def _on_retrain_done(self, new_acc):
        self._set_status(f"CNN æ¨¡å‹ä½¿ç”¨åé¦ˆæ•°æ®å†è®­ç»ƒå®Œæˆï¼æ–°çš„æµ‹è¯•å‡†ç¡®ç‡: {new_acc:.4f}")
        QMessageBox.information(self, "å†è®­ç»ƒå®Œæˆ",
                                f"CNN æ¨¡å‹å·²ä½¿ç”¨åé¦ˆæ•°æ®æ›´æ–°ï¼\næ–°çš„æµ‹è¯•å‡†ç¡®ç‡: {new_acc:.4f}")
        # é‡æ–°åŠ è½½æ›´æ–°åçš„æ¨¡å‹
        try:
            from tensorflow.keras.models import load_model
            self.model = load_model(MODEL_CNN)
            self._set_status(f"{self.model_type} æ¨¡å‹å·²é‡æ–°åŠ è½½ (ä½¿ç”¨åé¦ˆæ•°æ®æ›´æ–°)")
        except Exception as e:
            self._set_status(f"é‡æ–°åŠ è½½æ¨¡å‹å¤±è´¥ï¼š{e}", True)
        # æ¸…ç©ºåé¦ˆæ± 
        self.feedback_data = []
        self._set_status(f"åé¦ˆæ± å·²æ¸…ç©ºã€‚")


def main():
    app = QApplication(sys.argv)
    win = MainWindow()
    win.show()
    sys.exit(app.exec_())


if __name__ == "__main__":
    main()